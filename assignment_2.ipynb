{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X AND Y(W) before transpose  (800, 4)    (800,)\n",
      "Shape of the X AND Y(W) after transpose  (4, 800)    (1, 800)\n",
      "shape of X,Y,W (572, 4) (572, 1) (1, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(X):\n",
    "    return (1.0 / (1 + np.exp(-X)))\n",
    "\n",
    "def prediction(X,Y,W,b):\n",
    "\n",
    "    print(\"shape of X,Y,W\",X.shape,Y.shape,W.shape)\n",
    "    for i in range(500):\n",
    "        z = np.dot(W,X[i].T)+b\n",
    "        activation = sigmoid(z)\n",
    "        label = 0 if activation <0.5 else 1\n",
    "#(\"activation={}; predicted_label={}, true_label={}\".format(activation, label, Y[i]))\n",
    "def logistic_regressor():\n",
    "    b = 1\n",
    "    split = 800\n",
    "    alpha = 0.1\n",
    "    Adata_set = np.genfromtxt(\"dataset.csv\",delimiter = ',')\n",
    "    np.random.shuffle(Adata_set)\n",
    "    \n",
    "\n",
    "    #Separating Training Data ans Test data\n",
    "    train,test = Adata_set[:split,:],Adata_set[split:,:]\n",
    "    \n",
    "    W = np.array([0.1,0.2,0.4,0.6],dtype = 'f')\n",
    "    W = np.array([W])\n",
    "    \n",
    "    #Now slicing the input data and output data\n",
    "    X,Y = train[:,:-1],train[:,-1]\n",
    "    print(\"Shape of the X AND Y(W) before transpose \",X.shape,\"  \",Y.shape)\n",
    "    X = X.T\n",
    "    Y = np.array([Y])\n",
    "    m = np.prod(X.shape)\n",
    "    print(\"Shape of the X AND Y(W) after transpose \",X.shape,\"  \",Y.shape)\n",
    "\n",
    "    for i in range(10000):\n",
    "        Z = np.dot(W,X) + b\n",
    "\n",
    "        #calculating the sigmoid\n",
    "        A = sigmoid(Z)\n",
    "        \n",
    "        #calculating the derivative W.R to W\n",
    "        dz = A - Y\n",
    "        error = np.sum(dz**2)\n",
    "        #print(\"Training error is \",error)\n",
    "        #calculating the derivative \n",
    "        dw = np.dot(X,Z.T)/m\n",
    "\n",
    "        #calculating derivative W.R to b\n",
    "        db = np.sum(dz)/m\n",
    "        \n",
    "        \n",
    "        #updating weights\n",
    "        W -= alpha*dw.T\n",
    "        #print(\"Weights after \",i,\" iteration  is \",W)\n",
    "        #updating broadcas parameter\n",
    "        b -= alpha*(db)\n",
    "        #print(\"b after \",i,\" iteration  is \",b)\n",
    "    New_X, New_Y = test[:,:-1],test[:,-1]\n",
    "    New_Y = np.array([New_Y])\n",
    "    prediction(New_X,New_Y.T,W,b)\n",
    "    \n",
    "\n",
    "logistic_regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
